{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshagrawal/Affective-Computing-IIITD/blob/main/AFC_A2_2018420_Vishesh_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLpY3u1oyusB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets,transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Ccpx0kviy2nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Academic/Sem8/Affective Computing/Assignment_2\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAeZIX73y_dB",
        "outputId": "2f7ed3c5-8ae1-4c59-f660-06c7c34f8cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Academic/Sem8/Affective Computing/Assignment_2\n",
            " AFC_A2_2018420.ipynb  \u001b[0m\u001b[01;36m'Assignment 2 data'\u001b[0m@\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DEVICE (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sEEYJue0_12",
        "outputId": "4ccb7a5e-6ea1-4bd3-91f3-f932b3acae69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading"
      ],
      "metadata": {
        "id": "H9ADWqqo2A5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Used to load images into tensor format and resized format\n",
        "transform = transforms.Compose([transforms.Resize((300,300)),transforms.ToTensor() ])"
      ],
      "metadata": {
        "id": "dfd8TTi2AE7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_data_path=\"/content/drive/MyDrive/Academic/Sem8/Affective Computing/Assignment_2/Assignment 2 data/Source\"\n",
        "target_data_path=\"/content/drive/MyDrive/Academic/Sem8/Affective Computing/Assignment_2/Assignment 2 data/Target\""
      ],
      "metadata": {
        "id": "EJxbu1z0zaWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dataset = datasets.ImageFolder(source_data_path,transform)"
      ],
      "metadata": {
        "id": "l0RXK9KKznaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dataset = datasets.ImageFolder(target_data_path,transform)"
      ],
      "metadata": {
        "id": "isnTeukW0oEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting source domain into train and test\n",
        "source_total_length = len(source_dataset)\n",
        "source_train_size= int(0.8*source_total_length)\n",
        "source_val_size= source_total_length - source_train_size\n",
        "\n",
        "source_train_set, source_val_set = torch.utils.data.random_split(source_dataset, [source_train_size,source_val_size])"
      ],
      "metadata": {
        "id": "AlUryuvo9Hdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting target domain intro train and test\n",
        "target_total_length = len(target_dataset)\n",
        "target_train_size= int(0.8*target_total_length)\n",
        "target_val_size= target_total_length - target_train_size\n",
        "\n",
        "target_train_set, target_val_set = torch.utils.data.random_split(target_dataset, [target_train_size,target_val_size])"
      ],
      "metadata": {
        "id": "UcQ3mdeJ-EBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs=8"
      ],
      "metadata": {
        "id": "M_RsAQnqMG0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_train_loader = torch.utils.data.DataLoader(source_train_set, batch_size=bs, shuffle=True)\n",
        "source_val_loader = torch.utils.data.DataLoader(source_val_set, batch_size=bs, shuffle=True)"
      ],
      "metadata": {
        "id": "Zbtt-Mfs9g7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_train_loader = torch.utils.data.DataLoader(target_train_set, batch_size=bs, shuffle=True)\n",
        "target_val_loader = torch.utils.data.DataLoader(target_val_set, batch_size=bs, shuffle=True)"
      ],
      "metadata": {
        "id": "sElolQWb-B6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source_loader = torch.utils.data.DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
        "# target_loader = torch.utils.data.DataLoader(target_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "e-Ag4ea00xyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "_SRpo45E2Dqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "import torchvision.models as models\n",
        "model_ft=models.vgg16(pretrained=True)\n",
        "model_ft.classifier[6].out_features=7\n",
        "model_ft = model_ft.to(device)\n",
        "#Loss function is Cross Entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate= 1e-4 \n",
        "#Using Adam Optimizer\n",
        "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "IraOIOHB13Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9xEo2ei37IQ",
        "outputId": "c41adef6-00bf-46e0-9cc9-159c9f4115a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_train_steps= len(source_train_set)//bs\n",
        "source_val_steps=len(source_val_set)//bs"
      ],
      "metadata": {
        "id": "3ontjp1FEuP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_train_steps= len(target_train_set)//bs\n",
        "target_val_steps=len(target_val_set)//bs"
      ],
      "metadata": {
        "id": "BCdIZLJ3c43N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=5"
      ],
      "metadata": {
        "id": "YnJHDCUxHRdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model on Source Domain"
      ],
      "metadata": {
        "id": "OOMOgpZ4WwMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "  model_ft.train()\n",
        "  total_train_loss=0\n",
        "  total_val_loss=0\n",
        "  train_correct=0\n",
        "  val_correct=0\n",
        "\n",
        "  for (x,y) in source_train_loader:\n",
        "    (x,y)=(x.to(device),y.to(device))\n",
        "    pred=model_ft(x)\n",
        "    loss=criterion(pred,y)\n",
        "    optimizer_ft.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_ft.step()\n",
        "    total_train_loss+=loss\n",
        "    train_correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  model_ft.eval()\n",
        "  for (x,y) in source_val_loader:\n",
        "    (x,y)=(x.to(device),y.to(device))\n",
        "    pred=model_ft(x)\n",
        "    loss=criterion(pred,y)\n",
        "    # optimizer_ft.zero_grad()\n",
        "    # loss.backward()\n",
        "    # optimizer_ft.step()\n",
        "    total_val_loss+=loss\n",
        "    val_correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  \n",
        "  avg_train_loss=total_train_loss/source_train_steps\n",
        "  avg_val_loss=total_train_loss/source_val_steps\n",
        "  train_correct = train_correct/len(source_train_set)\n",
        "  val_correct = val_correct/len(source_val_set)\n",
        "\n",
        "  print(\"Training Loss\",avg_train_loss)\n",
        "  print(\"Training Accuracy\",train_correct)\n",
        "  print(\"Val Loss\",avg_val_loss)\n",
        "  print(\"Val Accuracy\",val_correct)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmXmtH8zCAwy",
        "outputId": "bdccea89-caa9-4d5b-aa52-dc6aba858161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss tensor(0.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.9928571428571429\n",
            "Val Loss tensor(0.1300, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.7142857142857143\n",
            "Training Loss tensor(0.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.9785714285714285\n",
            "Val Loss tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.7285714285714285\n",
            "Training Loss tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.9857142857142858\n",
            "Val Loss tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.6857142857142857\n",
            "Training Loss tensor(0.1330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.95\n",
            "Val Loss tensor(0.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.6857142857142857\n",
            "Training Loss tensor(0.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.9892857142857143\n",
            "Val Loss tensor(0.1888, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.6857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=5"
      ],
      "metadata": {
        "id": "20WhJjxrdgRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model on Target Domain"
      ],
      "metadata": {
        "id": "3AfXKV1JW3jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "  model_ft.train()\n",
        "  total_train_loss=0\n",
        "  total_val_loss=0\n",
        "  train_correct=0\n",
        "  val_correct=0\n",
        "\n",
        "  for (x,y) in target_train_loader:\n",
        "    (x,y)=(x.to(device),y.to(device))\n",
        "    pred=model_ft(x)\n",
        "    loss=criterion(pred,y)\n",
        "    optimizer_ft.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer_ft.step()\n",
        "    total_train_loss+=loss\n",
        "    train_correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  model_ft.eval()\n",
        "  for (x,y) in target_val_loader:\n",
        "    (x,y)=(x.to(device),y.to(device))\n",
        "    pred=model_ft(x)\n",
        "    loss=criterion(pred,y)\n",
        "    # optimizer_ft.zero_grad()\n",
        "    # loss.backward()\n",
        "    # optimizer_ft.step()\n",
        "    total_val_loss+=loss\n",
        "    val_correct +=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  \n",
        "  avg_train_loss=total_train_loss/target_train_steps\n",
        "  avg_val_loss=total_train_loss/target_val_steps\n",
        "  train_correct = train_correct/len(target_train_set)\n",
        "  val_correct = val_correct/len(target_val_set)\n",
        "\n",
        "  print(\"Training Loss\",avg_train_loss)\n",
        "  print(\"Training Accuracy\",train_correct)\n",
        "  print(\"Val Loss\",avg_val_loss)\n",
        "  print(\"Val Accuracy\",val_correct)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUpIS3PiBRfX",
        "outputId": "27793df2-acea-4aa8-cf57-e7e563e3f527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss tensor(0.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 0.9642857142857143\n",
            "Val Loss tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.35714285714285715\n",
            "Training Loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 1.0\n",
            "Val Loss tensor(0.1047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.6428571428571429\n",
            "Training Loss tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 1.0\n",
            "Val Loss tensor(0.0088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.5714285714285714\n",
            "Training Loss tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 1.0\n",
            "Val Loss tensor(0.0058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.5714285714285714\n",
            "Training Loss tensor(0.0012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy 1.0\n",
            "Val Loss tensor(0.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Val Accuracy 0.6428571428571429\n"
          ]
        }
      ]
    }
  ]
}